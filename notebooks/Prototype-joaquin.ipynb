{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b6ea29",
   "metadata": {},
   "source": [
    "# Experiments related to Joaquin\n",
    "Technically, this notebook implements something *even dumber* than *Joaquin*.\n",
    "It implements kNN in *Gaia*-only quantities to get a weighted-mean estimate of schmag.\n",
    "\n",
    "## Authors:\n",
    "- **Adrian Price-Whelan** (Flatiron)\n",
    "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
    "\n",
    "## Definitions and Conventions:\n",
    "- `ncoeff`: The number of BP and RP spectral coefficients to use.\n",
    "- `maxk`: The maximum `k` to which we take neighbors.\n",
    "- scalings or preprocessing of input features (currently null).\n",
    "- how we use the neighbors (weighted mean, weighted linear fit, mixture of some kind?).\n",
    "\n",
    "## TODO / questions\n",
    "- Do we add \"Reduced proper motion\" as a feature?\n",
    "- Use 2MASS or WISE photometry in features?\n",
    "- Color the CMD by implied density (and store distance to Kth neighbor as proxy for density)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53898a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import astropy.coordinates as coord\n",
    "import astropy.table as at\n",
    "import astropy.units as u\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KDTree\n",
    "from pyia import GaiaData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac563c",
   "metadata": {},
   "source": [
    "Load APOGEE x Gaia data â€” see `Assemble-data.ipynb` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c916aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gall = GaiaData('../cache/apogee-dr17-x-gaia-dr3-xp.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEFF_lim = (4500, 5100)\n",
    "LOGG_lim = (2.3, 2.6)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "H, xb, yb, _ = ax.hist2d(\n",
    "    gall.TEFF,\n",
    "    gall.LOGG,\n",
    "    bins=(\n",
    "        np.linspace(3000, 8000, 128),\n",
    "        np.linspace(-0.5, 5.5, 128)\n",
    "    ),\n",
    "    norm=mpl.colors.LogNorm()\n",
    ")\n",
    "ax.set_xlim(xb.max(), xb.min())\n",
    "ax.set_ylim(yb.max(), yb.min())\n",
    "\n",
    "for l in TEFF_lim:\n",
    "    ax.axvline(l)\n",
    "for l in LOGG_lim:\n",
    "    ax.axhline(l)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gall.filter(\n",
    "    TEFF=TEFF_lim,\n",
    "    LOGG=LOGG_lim,\n",
    "    M_H=[-3, None],\n",
    "    phot_g_mean_mag=[None, 15.5*u.mag]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167badb6",
   "metadata": {},
   "source": [
    "## Make rectangular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does something useful!\n",
    "xp_apogee_tbl = xp_apogee_tbl.filled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(\n",
    "#     xp_apogee_tbl['phot_g_mean_mag'] - xp_apogee_tbl['J'],\n",
    "#     xp_apogee_tbl['AK_WISE'],\n",
    "#     ls='none',\n",
    "#     ms=1., mew=0, alpha=0.2\n",
    "# )\n",
    "# plt.xlim(-1, 8)\n",
    "# plt.ylim(-0.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make rectangular block of Gaia-only features (X) for training and validation\n",
    "\n",
    "# APW, HOGG: BUG: Why these cuts?\n",
    "feature_mask = (\n",
    "#     (xp_apogee_tbl['J'] < 13) &\n",
    "#     (xp_apogee_tbl['H'] < 12) &\n",
    "#     (xp_apogee_tbl['K'] < 11) &\n",
    "    (xp_apogee_tbl['AK_WISE'] > 0) &\n",
    "    (np.abs(xp_apogee_tbl['b']) > 30.)\n",
    ")\n",
    "\n",
    "ncoeff = 54 # MAGIC\n",
    "xx = (xp_apogee_tbl['bp'][:, 1:ncoeff + 1] / xp_apogee_tbl['bp'][:, 0:1])[feature_mask]\n",
    "yy = (xp_apogee_tbl['rp'][:, 1:ncoeff + 1] / xp_apogee_tbl['rp'][:, 0:1])[feature_mask]\n",
    "coeffs = np.vstack([[xx[:, i], yy[:, i]] for i in range(ncoeff)]).T\n",
    "coeff_names = np.concatenate([[f'BP[{i}]', f'RP[{i}]'] for i in range(1, ncoeff + 1)])\n",
    "\n",
    "features = np.hstack((\n",
    "    0.1 * (xp_apogee_tbl['phot_bp_mean_mag'] - xp_apogee_tbl['phot_rp_mean_mag'])[feature_mask, None],\n",
    "    # (xp_apogee_tbl['phot_g_mean_mag'] - xp_apogee_tbl['phot_rp_mean_mag'])[feature_mask, None],\n",
    "#     0.2 * (xp_apogee_tbl['phot_g_mean_mag'] - xp_apogee_tbl['J'])[feature_mask, None],\n",
    "    coeffs\n",
    "))\n",
    "coeff_idx = 1\n",
    "# features = coeffs\n",
    "# coeff_idx = 0\n",
    "\n",
    "feature_names = np.concatenate((\n",
    "    ['$BP-RP$ [mag]', ],\n",
    "#     ['$G-J$ [mag]', ],\n",
    "    coeff_names\n",
    "))\n",
    "# feature_names = coeff_names\n",
    "\n",
    "print(features.shape)\n",
    "print(len(feature_names), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "plx_mask = (xp_apogee_tbl[feature_mask]['parallax_over_error'] > 5)\n",
    "\n",
    "_tbl = xp_apogee_tbl[feature_mask]\n",
    "DM = coord.Distance(parallax=_tbl['parallax'].value * u.mas, allow_negative=True).distmod\n",
    "bprp = _tbl['phot_bp_mean_mag'] - _tbl['phot_rp_mean_mag']\n",
    "mg = _tbl['phot_g_mean_mag'] - DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BP[1] and RP[1] are very correlated with BP-RP, even after scaling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].plot(\n",
    "    bprp,\n",
    "    coeffs[:, 0],\n",
    "    ls='none'\n",
    ")\n",
    "axes[1].plot(\n",
    "    bprp,\n",
    "    coeffs[:, 1],\n",
    "    ls='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# things = np.nanpercentile(features, [5, 95], axis=0)\n",
    "# plt.hist(things[1] - things[0], bins=np.linspace(0, things.max(), 32));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.hist(\n",
    "#     xp_apogee_tbl['phot_g_mean_mag'][feature_mask], \n",
    "#     bins=np.linspace(5, 20.7, 121)\n",
    "# );\n",
    "# plt.xlabel('$G$ [mag]')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb634c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK / TEST: remove temperature dependence of coefficient prediction\n",
    "# M = np.hstack((\n",
    "#     np.ones((features.shape[0], 1)),\n",
    "#     coeffs\n",
    "# ))\n",
    "# M = coeffs\n",
    "\n",
    "# # sol, *_ = np.linalg.lstsq(M, xp_apogee_tbl['TEFF'][feature_mask], rcond=None)\n",
    "# sol, *_ = np.linalg.lstsq(M, bprp, rcond=None)\n",
    "\n",
    "# corrected = M - M.dot(sol)[:, None] * sol[None]\n",
    "# # corrected = corrected[:, 1:]\n",
    "# features = np.hstack((\n",
    "#     features[:, :coeff_idx],\n",
    "#     corrected\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BP[1] and RP[1] are very correlated with BP-RP, even after scaling\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# axes[0].plot(\n",
    "#     bprp,\n",
    "#     corrected[:, 0],\n",
    "#     ls='none'\n",
    "# )\n",
    "# axes[1].plot(\n",
    "#     bprp,\n",
    "#     corrected[:, 1],\n",
    "#     ls='none'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93bcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of labels (and label weights), aligned with the features.\n",
    "# labels = (xp_apogee_tbl['parallax'] * 10 ** (1/5 * xp_apogee_tbl['phot_g_mean_mag']))[feature_mask]\n",
    "labels = xp_apogee_tbl['M_H'][feature_mask]\n",
    "print(labels.shape)\n",
    "\n",
    "# label_errors = (xp_apogee_tbl['parallax_error'] * 10 ** (1/5 * xp_apogee_tbl['phot_g_mean_mag']))[feature_mask]\n",
    "label_errors = xp_apogee_tbl['M_H_ERR'][feature_mask]\n",
    "print(label_errors.shape)\n",
    "\n",
    "label_weights = 1. / (label_errors ** 2)\n",
    "print(label_weights.shape)\n",
    "\n",
    "label_name = '$G$-band schmag (absmgy$^{-1/2}$)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the labels aren't wack\n",
    "bins = (\n",
    "    np.linspace(-300, 1000, 128),\n",
    "    np.linspace(-10, 200, 128)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# ax.scatter(labels, labels / label_errors, c=\"k\", s=1., alpha=0.05)\n",
    "ax.hist2d(\n",
    "    labels, \n",
    "    labels / label_errors, \n",
    "    bins=bins,\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    cmap='Greys'\n",
    ")\n",
    "\n",
    "ax.axhline(np.median(labels / label_errors), color=\"k\", ls='--')\n",
    "ax.set_xlim(bins[0].min(), bins[0].max())\n",
    "ax.set_ylim(bins[1].min(), bins[1].max())\n",
    "ax.set_xlabel(label_name)\n",
    "ax.set_ylabel(\"label SNR\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1545f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the features aren't wack\n",
    "\n",
    "for i in range(min(features.shape[1], 8)):\n",
    "    f = plt.figure()\n",
    "    foo = np.percentile(features[:, i], [2.5, 97.5])\n",
    "    lo = 0.5 * (foo[1] + foo[0]) - (foo[1] - foo[0])\n",
    "    hi = 0.5 * (foo[1] + foo[0]) + (foo[1] - foo[0])\n",
    "    # plt.scatter(features[:, i], labels, c=\"k\", s=1., alpha=0.05)\n",
    "    bins = (\n",
    "        np.linspace(*np.nanpercentile(features[:, i], [1e-1, 100-1e-1]), 128),\n",
    "        np.linspace(-300, 1200, 128)\n",
    "    )\n",
    "    plt.hist2d(features[:, i], labels, bins=bins, \n",
    "               cmap='Greys', norm=mpl.colors.LogNorm())\n",
    "    plt.xlim(lo, hi)\n",
    "    plt.ylim(bins[1].min(), bins[1].max())\n",
    "    plt.xlabel(feature_names[i])\n",
    "    plt.ylabel(label_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99758742",
   "metadata": {},
   "source": [
    "## Make training and validation samples\n",
    "\n",
    "cut into eighths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5941dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "rando = rng.integers(8, size=len(features))\n",
    "train = rando != 0\n",
    "valid = ~train\n",
    "\n",
    "X_train, X_valid = features[train], features[valid]\n",
    "Y_train, Y_valid = labels[train], labels[valid]\n",
    "W_train, W_valid = label_weights[train], label_weights[valid]\n",
    "\n",
    "print(X_train.shape, X_valid.shape)\n",
    "print(Y_train.shape, Y_valid.shape)\n",
    "print(W_train.shape, W_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf30fc1",
   "metadata": {},
   "source": [
    "## Build a kNN model and validate it\n",
    "\n",
    "Get all possibly useful validation-set neighbors up-front.\n",
    "We'll use them in various ways below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxk = 64  # MAGIC  \n",
    "# P_tree = 2 * 5 + 1  # MAGIC\n",
    "P_tree = 2 * 15 + 1  # MAGIC\n",
    "tree = KDTree(X_train[:, :P_tree], leaf_size=32) # magic\n",
    "dists, inds = tree.query(X_valid[:, :P_tree], k=maxk)\n",
    "print(X_valid.shape, dists.shape, inds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = 2 ** np.arange(0, int(np.log2(maxk)) + 1, 2)\n",
    "ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5954e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement weighted-mean method for KNN.\n",
    "weighted_means = {}\n",
    "weighted_errs = {}\n",
    "for k in ks:\n",
    "    assert k <= maxk\n",
    "    weighted_means[k] = (\n",
    "        np.sum(Y_train[inds[:, :k]] * W_train[inds[:, :k]], axis=1) / \n",
    "        np.sum(W_train[inds[:, :k]], axis=1)\n",
    "    )\n",
    "    weighted_errs[k] = np.sqrt(1 / np.sum(W_train[inds[:, :k]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x):\n",
    "    x = np.array(x)\n",
    "    return (x - x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a few objects\n",
    "cmap = plt.get_cmap('turbo')\n",
    "\n",
    "for ii in range(8):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(11, 5))\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.axhline(Y_valid[ii], c=\"r\")\n",
    "    ax.axhspan(\n",
    "        Y_valid[ii] - 1 / np.sqrt(W_valid[ii]),\n",
    "        Y_valid[ii] + 1 / np.sqrt(W_valid[ii]),\n",
    "        color='r', alpha=0.25, linewidth=0\n",
    "    )\n",
    "    \n",
    "    colors = cmap(scale(np.log(list(weighted_means.keys()))))\n",
    "    for color, (kk, mean) in zip(colors, weighted_means.items()):\n",
    "        ax.axhline(mean[ii], linestyle='--', alpha=0.4, color=color)\n",
    "        ax.axhspan(\n",
    "            mean[ii] - weighted_errs[kk][ii],\n",
    "            mean[ii] + weighted_errs[kk][ii],\n",
    "            alpha=0.4, color=color, linewidth=0\n",
    "        )\n",
    "    \n",
    "    ax.errorbar(dists[ii], \n",
    "                 Y_train[inds[ii]], \n",
    "                 yerr=1. / np.sqrt(W_train[inds[ii]]),\n",
    "                 fmt=\"o\", color=\"k\", ecolor=\"k\")\n",
    "    ax.set_xlabel(\"distance to neighbor\")\n",
    "    ax.set_ylabel(\"label of neighbor\")\n",
    "    ax.set_title(f\"validation-set object {ii}\")\n",
    "    \n",
    "    # ---\n",
    "    \n",
    "    ax = axes[1]\n",
    "    \n",
    "    bins = (\n",
    "        np.linspace(-0.5, 3.5, 128),\n",
    "        np.linspace(-4, 12, 128)\n",
    "    )\n",
    "    ax.hist2d(\n",
    "        bprp,\n",
    "        mg,\n",
    "        bins=bins,\n",
    "        cmap='Greys',\n",
    "        norm=mpl.colors.LogNorm()\n",
    "    )\n",
    "    ax.scatter(\n",
    "        bprp[valid][ii],\n",
    "        mg[valid][ii],\n",
    "        s=10,\n",
    "        color='tab:red',\n",
    "        zorder=100\n",
    "    )\n",
    "    ax.scatter(\n",
    "        bprp[train][inds[ii]],\n",
    "        mg[train][inds[ii]],\n",
    "        s=4,\n",
    "        color='tab:blue',\n",
    "        alpha=0.5,\n",
    "        zorder=10\n",
    "    )\n",
    "    ax.set_xlim(0., 4.)\n",
    "    ax.set_ylim(10, -4)\n",
    "    \n",
    "    ax.set_xlabel('$G_{BP}-G_{RP}$')\n",
    "    ax.set_ylabel('$M_G$')\n",
    "    \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e6d24",
   "metadata": {},
   "source": [
    "CMD colored by discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "for color, (kk, Y_pred) in zip(colors, weighted_means.items()):\n",
    "#     dy = (Y_valid - Y_pred) / Y_valid\n",
    "    dy = (Y_valid - Y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    cs = ax.scatter(\n",
    "        bprp[valid],\n",
    "        mg[valid],\n",
    "        c=dy,\n",
    "        vmin=-.25, vmax=.25,\n",
    "        cmap='RdBu',\n",
    "        s=2\n",
    "    )\n",
    "    ax.set_xlim(0., 4.)\n",
    "    ax.set_ylim(10, -4)\n",
    "    \n",
    "    cb = fig.colorbar(cs)\n",
    "    \n",
    "    ax.set_xlabel('$G_{BP}-G_{RP}$')\n",
    "    ax.set_ylabel('$M_G$')\n",
    "    ax.set_title(f'K={kk}')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement weighted linear least-squares method for KNN.\n",
    "ks = 2 ** np.arange(0, int(np.log2(maxk)) + 1, 2)\n",
    "Ps = [3, 11, 33, 101]\n",
    "\n",
    "X_fit_train = np.hstack((np.ones(X_train.shape[0])[:, None], X_train))\n",
    "N, P = X_fit_train.shape\n",
    "\n",
    "X_fit_valid = np.hstack((np.ones(X_valid.shape[0])[:, None], X_valid))\n",
    "Nvalid, Pvalid = X_fit_valid.shape\n",
    "\n",
    "assert Pvalid == P\n",
    "\n",
    "Y_valid_preds = {(P, k): np.zeros(Nvalid) for k in ks for P in Ps}\n",
    "# weighted_lls_errs = {}\n",
    "\n",
    "# TODO: Regularization\n",
    "alpha = 1e-8\n",
    "\n",
    "for P in Ps:\n",
    "    L = np.eye(P) * alpha\n",
    "    Linv = np.eye(P) * 1 / alpha\n",
    "\n",
    "    for k in ks:\n",
    "        assert k <= maxk\n",
    "\n",
    "        # TODO: switch to linalg.lstsq when you hit singular matrix shit\n",
    "        for ii, ind in tqdm(enumerate(inds[:, :k]), total=Nvalid):\n",
    "            slc = (ind, slice(None, P))\n",
    "            \n",
    "            C_train = np.diag(1 / W_train[ind])\n",
    "            Cinv_train = np.diag(W_train[ind])\n",
    "\n",
    "            if k > P:\n",
    "                Y_valid_preds[P, k][ii] = (\n",
    "                    X_fit_valid[ii, :P] @ np.linalg.solve(\n",
    "                        X_fit_train[slc].T @ Cinv_train @ X_fit_train[slc] + L,\n",
    "                        X_fit_train[slc].T @ Cinv_train @ Y_train[ind]\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                Y_valid_preds[P, k][ii] = (\n",
    "                    X_fit_valid[ii, :P] @ Linv @ X_fit_train[slc].T @ np.linalg.solve(\n",
    "                        X_fit_train[slc] @ Linv @ X_fit_train[slc].T + C_train,\n",
    "                        Y_train[ind]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # BUG: The next line is WRONG\n",
    "    #     weighted_lls_errs[k] = np.sqrt(1 / np.sum(W_train[inds[:, :k]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    len(ks), len(Ps), \n",
    "    figsize=(12, 12),\n",
    "    sharex=True, sharey=True,\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "for i, P in enumerate(Ps):\n",
    "    for j, k in enumerate(ks):\n",
    "        ax = axes[j, i]\n",
    "        \n",
    "        # dy = (Y_valid - Y_valid_preds[P, k]) / Y_valid\n",
    "        dy = (Y_valid - Y_valid_preds[P, k]) \n",
    "\n",
    "        _cs = ax.scatter(\n",
    "            bprp[valid],\n",
    "            mg[valid],\n",
    "            c=dy,\n",
    "            vmin=-0.25, vmax=0.25,\n",
    "            cmap='RdBu',\n",
    "            s=1\n",
    "        )\n",
    "\n",
    "        ax.set_xlim(0., 4.)\n",
    "        ax.set_ylim(10, -4)\n",
    "\n",
    "        ax.set_title(f'K={k}, P={P}')\n",
    "\n",
    "for ax in axes[-1]:\n",
    "    ax.set_xlabel('$G_{BP}-G_{RP}$')\n",
    "for ax in axes[:, 0]:\n",
    "    ax.set_ylabel('$M_G$')\n",
    "\n",
    "cb = fig.colorbar(_cs, ax=axes, aspect=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _cs = plt.scatter(\n",
    "#     bprp[valid],\n",
    "#     mg[valid],\n",
    "#     c=Y_valid_preds[3, 64] - Y_valid_preds[101, 64],\n",
    "#     vmin=-10, vmax=10,\n",
    "#     cmap='RdBu',\n",
    "#     s=1\n",
    "# )\n",
    "\n",
    "# plt.xlim(0., 4.)\n",
    "# plt.ylim(10, -4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1bc441",
   "metadata": {},
   "source": [
    "2D \"image\" of P vs K, colored by metric (MAD, RMS) in MS box and RGB box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_boxes = {\n",
    "    'ms': (\n",
    "        (np.abs(bprp - 1.5) < 0.5) &\n",
    "        (np.abs(mg.value - 7) < 0.5)\n",
    "    ),\n",
    "    'rc': (\n",
    "        (np.abs(bprp - 1.2) < 0.5) &\n",
    "        (np.abs(mg.value - 0.9) < 0.5)\n",
    "    ),\n",
    "    'rgb': (\n",
    "        (np.abs(bprp - 1.2) < 0.5) &\n",
    "        (np.abs(mg.value - 1) < 0.5)\n",
    "    ),\n",
    "    'trgb': (\n",
    "        (bprp > 1) &\n",
    "        (bprp < 4) &\n",
    "        (np.abs(mg.value - -1) < 0.5)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "for name, box_mask in stat_boxes.items():\n",
    "    stats[name] = np.zeros((len(Ps), len(ks)))\n",
    "    for i, P in enumerate(Ps):\n",
    "        for j, k in enumerate(ks):\n",
    "            chi = (np.sqrt(W_valid) * (Y_valid - Y_valid_preds[P, k]))[box_mask[valid]].value\n",
    "            meanchi2 = np.mean(chi**2)\n",
    "            medchi2 = np.median(chi**2)\n",
    "\n",
    "#             stats[name][i, j] = meanchi2\n",
    "            stats[name][i, j] = medchi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47685497",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(11, 10), \n",
    "                         sharex=True, sharey=True,\n",
    "                         constrained_layout=True)\n",
    "for ax, (name, stat) in zip(axes.flat, stats.items()):\n",
    "    _cs = ax.imshow(stat.T, cmap='turbo', origin='lower')\n",
    "    fig.colorbar(_cs, ax=ax)\n",
    "    ax.set_xlabel('$P$')\n",
    "    ax.set_ylabel('$k$')\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(Ps)))\n",
    "    ax.set_yticks(np.arange(len(ks)))\n",
    "    ax.set_xticklabels([str(x) for x in Ps])\n",
    "    ax.set_yticklabels([str(x) for x in ks])\n",
    "    \n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea716f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, stat in stats.items():\n",
    "#     fig, ax = plt.subplots(figsize=(6.5, 5.5), constrained_layout=True)\n",
    "#     _cs = plt.imshow(stat.T, cmap='turbo', origin='lower')\n",
    "#     fig.colorbar(_cs, ax=ax)\n",
    "#     ax.set_xlabel('$P$')\n",
    "#     ax.set_ylabel('$k$')\n",
    "    \n",
    "#     ax.set_xticks(np.arange(len(Ps)))\n",
    "#     ax.set_yticks(np.arange(len(ks)))\n",
    "#     ax.set_xticklabels([str(x) for x in Ps])\n",
    "#     ax.set_yticklabels([str(x) for x in ks])\n",
    "    \n",
    "#     ax.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc839969",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8814e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_mask[valid].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a linear weighted least squares as a function of k\n",
    "# HOGG: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some kind of mixture model maybe??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8ec2a",
   "metadata": {},
   "source": [
    "## Run this model on EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86404e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APW: We need to figure out the above tests and then run in the data center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f8897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735673a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adrian conda base",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
