{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b6ea29",
   "metadata": {},
   "source": [
    "# Experiments related to Joaquin\n",
    "Technically, this notebook implements something *even dumber* than *Joaquin*.\n",
    "It implements kNN in *Gaia*-only quantities to get a weighted-mean estimate of schmag.\n",
    "\n",
    "## Authors:\n",
    "- **Adrian Price-Whelan** (Flatiron)\n",
    "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
    "\n",
    "## Definitions and Conventions:\n",
    "- `ncoeff`: The number of BP and RP spectral coefficients to use.\n",
    "- `maxk`: The maximum `k` to which we take neighbors.\n",
    "- scalings or preprocessing of input features (currently null).\n",
    "- how we use the neighbors (weighted mean, weighted linear fit, mixture of some kind?).\n",
    "\n",
    "## TODO / questions\n",
    "- Do we add \"Reduced proper motion\" as a feature?\n",
    "- Use 2MASS or WISE photometry in features?\n",
    "- Color the CMD by implied density (and store distance to Kth neighbor as proxy for density)\n",
    "- Predict [M/H] or LOGG, then feed back in as a feature to predict schmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53898a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import astropy.coordinates as coord\n",
    "from astropy.stats import median_absolute_deviation as MAD\n",
    "import astropy.table as at\n",
    "import astropy.units as u\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KDTree\n",
    "from pyia import GaiaData\n",
    "\n",
    "from helpers import load_data, Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12678364",
   "metadata": {},
   "source": [
    "Load APOGEE x Gaia data â€” see `Assemble-data.ipynb` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = load_data()\n",
    "\n",
    "# For red clump instead:\n",
    "g = load_data(\n",
    "    filters=dict(\n",
    "        TEFF=(4500, 5100), \n",
    "        LOGG=(2.3, 2.6),\n",
    "        M_H=(-3, None),\n",
    "        phot_g_mean_mag=(None, 15.5*u.mag),\n",
    "        AK_WISE=(-0.1, None)\n",
    "    )\n",
    ")\n",
    "g = g[(np.abs(g.b) > 15*u.deg) & (g.SFD_EBV < 0.2)]\n",
    "\n",
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bprp = (g.phot_bp_mean_mag - g.phot_rp_mean_mag).value\n",
    "mg = (g.phot_g_mean_mag - g.get_distance(allow_negative=True).distmod).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "H, xb, yb, _ = ax.hist2d(\n",
    "    g.TEFF,\n",
    "    g.LOGG,\n",
    "    bins=(\n",
    "        np.linspace(3000, 8000, 128),\n",
    "        np.linspace(-0.5, 5.5, 128)\n",
    "    ),\n",
    "    norm=mpl.colors.LogNorm()\n",
    ")\n",
    "ax.set_xlim(xb.max(), xb.min())\n",
    "ax.set_ylim(yb.max(), yb.min())\n",
    "ax.set_xlabel('TEFF')\n",
    "ax.set_ylabel('LOGG')\n",
    "\n",
    "ax = axes[1]\n",
    "H, xb, yb, _ = ax.hist2d(\n",
    "    bprp,\n",
    "    mg,\n",
    "    bins=(\n",
    "        np.linspace(-0.5, 3, 128),\n",
    "        np.linspace(-4, 10.5, 128)\n",
    "    ),\n",
    "    norm=mpl.colors.LogNorm()\n",
    ")\n",
    "ax.set_xlim(xb.min(), xb.max())\n",
    "ax.set_ylim(yb.max(), yb.min())\n",
    "ax.set_xlabel('BP-RP')\n",
    "ax.set_ylabel('$M_G$')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d8b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = {\n",
    "    r\"$G_{\\rm BP}-G_{\\rm RP}$\": 0.1 * (g.phot_bp_mean_mag - g.phot_rp_mean_mag)\n",
    "}\n",
    "f_all = Features.from_gaiadata(g, n_bp=25, n_rp=25, **other_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f52adf2",
   "metadata": {},
   "source": [
    "Make list of possible labels (and label weights), aligned with the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93bcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of labels (and label weights), aligned with the features.\n",
    "\n",
    "label_ys = {}\n",
    "label_weights = {}\n",
    "label_latex = {}\n",
    "\n",
    "schmag_factor = 10 ** (0.2 * g.phot_g_mean_mag.value) / 100.\n",
    "schmag_err = g.parallax_error.value * schmag_factor\n",
    "label_ys['schmag'] = g.parallax.value * schmag_factor\n",
    "label_weights['schmag'] = 1 / schmag_err**2\n",
    "label_latex['schmag'] = '$G$-band schmag (absmgy$^{-1/2}$)'\n",
    "\n",
    "for name in ['M_H', 'LOGG', 'TEFF', 'AK_WISE']:\n",
    "    err_col = f'{name}_ERR'\n",
    "    label_ys[name] = g[name]\n",
    "    if err_col in g.data.colnames:\n",
    "        label_weights[name] = 1 / g[err_col]**2\n",
    "    else:\n",
    "        label_weights[name] = np.ones_like(label_ys[name])\n",
    "\n",
    "label_latex['M_H'] = r\"$[{\\rm M}/{\\rm H}]$\"\n",
    "label_latex['LOGG'] = r\"$\\log g$\"\n",
    "label_latex['TEFF'] = r\"$T_{\\rm eff}$\"\n",
    "label_latex['AK_WISE'] = r\"$A_K$\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d83cee7",
   "metadata": {},
   "source": [
    "Check the label uncertainties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed016101",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = int(np.ceil(len(label_ys) / 2))\n",
    "fig, axes = plt.subplots(\n",
    "    2, \n",
    "    ny, \n",
    "    figsize=(5 * ny, 8)\n",
    ")\n",
    "\n",
    "for ax, name in zip(axes.flat, label_ys.keys()):\n",
    "    y = label_ys[name]\n",
    "    yerr = 1 / np.sqrt(label_weights[name])\n",
    "    \n",
    "    bins = [\n",
    "        np.linspace(*np.percentile(y, [1, 99]), 128),\n",
    "        np.geomspace(*np.percentile(yerr, [1, 99]), 128)\n",
    "    ]\n",
    "    if name == 'AK_WISE':\n",
    "        bins[1] = np.geomspace(0.5, 2, 128)\n",
    "        \n",
    "    ax.hist2d(\n",
    "        y, \n",
    "        yerr, \n",
    "        bins=bins,\n",
    "        norm=mpl.colors.LogNorm(),\n",
    "        cmap='Greys'\n",
    "    )\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    _label = label_latex[name]\n",
    "    ax.set_xlabel(_label)\n",
    "    ax.set_ylabel(r'$\\sigma$ ' + _label)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99758742",
   "metadata": {},
   "source": [
    "## Make training and validation samples\n",
    "\n",
    "cut into eighths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5941dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'schmag'\n",
    "# label_name = 'LOGG'\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "rando = rng.integers(8, size=len(f_all))\n",
    "train = rando != 0\n",
    "valid = (\n",
    "    ~train &\n",
    "#     (g.LOGG < 2.2) &\n",
    "    ((label_ys[label_name] * np.sqrt(label_weights[label_name])) > 8)\n",
    ")\n",
    "\n",
    "f_train = f_all[train]\n",
    "f_valid = f_all[valid]\n",
    "\n",
    "X_train, X_valid = f_train.X, f_valid.X\n",
    "y_train, y_valid = label_ys[label_name][train], label_ys[label_name][valid]\n",
    "w_train, w_valid = label_weights[label_name][train], label_weights[label_name][valid]\n",
    "\n",
    "print(X_train.shape, X_valid.shape)\n",
    "print(y_train.shape, y_valid.shape)\n",
    "print(w_train.shape, w_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf30fc1",
   "metadata": {},
   "source": [
    "## Build a kNN model and validate it\n",
    "\n",
    "Get all possibly useful validation-set neighbors up-front.\n",
    "We'll use them in various ways below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxK = 1024  # MAGIC  \n",
    "P_tree = 64  # MAGIC\n",
    "tree = KDTree(X_train[:, :P_tree], leaf_size=32) # magic\n",
    "dists, inds = tree.query(X_valid[:, :P_tree], k=maxK)\n",
    "print(X_valid.shape, dists.shape, inds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = 2 ** np.arange(0, int(np.log2(maxK)) + 1, 2)\n",
    "Ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e871177",
   "metadata": {},
   "source": [
    "# Weighted means of $K$ neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5954e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_means = {}\n",
    "weighted_errs = {}\n",
    "for k in Ks:\n",
    "    weighted_means[k] = (\n",
    "        np.sum(y_train[inds[:, :k]] * w_train[inds[:, :k]], axis=1) / \n",
    "        np.sum(w_train[inds[:, :k]], axis=1)\n",
    "    )\n",
    "    weighted_errs[k] = np.sqrt(1 / np.sum(w_train[inds[:, :k]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x):\n",
    "    x = np.array(x)\n",
    "    return (x - x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a few objects\n",
    "cmap = plt.get_cmap('turbo')\n",
    "\n",
    "for ii in range(8):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(11, 5))\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.axhline(y_valid[ii], c=\"r\")\n",
    "    ax.axhspan(\n",
    "        y_valid[ii] - 1 / np.sqrt(w_valid[ii]),\n",
    "        y_valid[ii] + 1 / np.sqrt(w_valid[ii]),\n",
    "        color='r', alpha=0.25, linewidth=0\n",
    "    )\n",
    "    \n",
    "    colors = cmap(scale(np.log(list(weighted_means.keys()))))\n",
    "    for color, (kk, mean) in zip(colors, weighted_means.items()):\n",
    "        ax.axhline(mean[ii], linestyle='--', alpha=0.4, color=color)\n",
    "        ax.axhspan(\n",
    "            mean[ii] - weighted_errs[kk][ii],\n",
    "            mean[ii] + weighted_errs[kk][ii],\n",
    "            alpha=0.4, color=color, linewidth=0\n",
    "        )\n",
    "    \n",
    "    ax.errorbar(dists[ii], \n",
    "                y_train[inds[ii]], \n",
    "                yerr=1. / np.sqrt(w_train[inds[ii]]),\n",
    "                fmt=\"o\", color=\"k\", ecolor=\"k\")\n",
    "    ax.set_xlabel(\"distance to neighbor\")\n",
    "    ax.set_ylabel(\"label of neighbor\")\n",
    "    ax.set_title(f\"validation-set object {ii}\")\n",
    "    \n",
    "    # ---\n",
    "    \n",
    "    ax = axes[1]\n",
    "    \n",
    "    bins = (\n",
    "        np.linspace(-0.5, 3.5, 128),\n",
    "        np.linspace(-4, 12, 128)\n",
    "    )\n",
    "    ax.hist2d(\n",
    "        bprp,\n",
    "        mg,\n",
    "        bins=bins,\n",
    "        cmap='Greys',\n",
    "        norm=mpl.colors.LogNorm()\n",
    "    )\n",
    "    ax.scatter(\n",
    "        bprp[valid][ii],\n",
    "        mg[valid][ii],\n",
    "        s=10,\n",
    "        color='tab:red',\n",
    "        zorder=100\n",
    "    )\n",
    "    ax.scatter(\n",
    "        bprp[train][inds[ii]],\n",
    "        mg[train][inds[ii]],\n",
    "        s=4,\n",
    "        color='tab:blue',\n",
    "        alpha=0.5,\n",
    "        zorder=10\n",
    "    )\n",
    "    ax.set_xlim(0., 4.)\n",
    "    ax.set_ylim(10, -4)\n",
    "    \n",
    "    ax.set_xlabel('$G_{BP}-G_{RP}$')\n",
    "    ax.set_ylabel('$M_G$')\n",
    "    \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e6d24",
   "metadata": {},
   "source": [
    "CMD colored by discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "for color, (kk, y_pred) in zip(colors, weighted_means.items()):\n",
    "#     dy = (Y_valid - Y_pred) / Y_valid\n",
    "    dy = (y_valid - y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    cs = ax.scatter(\n",
    "        bprp[valid],\n",
    "        mg[valid],\n",
    "        c=dy,\n",
    "        vmin=-.25, vmax=.25,\n",
    "        cmap='RdBu',\n",
    "        s=2\n",
    "    )\n",
    "    ax.set_xlim(0., 4.)\n",
    "    ax.set_ylim(10, -4)\n",
    "    \n",
    "    cb = fig.colorbar(cs)\n",
    "    \n",
    "    ax.set_xlabel('$G_{BP}-G_{RP}$')\n",
    "    ax.set_ylabel('$M_G$')\n",
    "    ax.set_title(f'K={kk}')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ac274",
   "metadata": {},
   "source": [
    "Red clump test: How do we do just predicting the mean over the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594724f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred = (\n",
    "    np.sum(y_train * w_train) / \n",
    "    np.sum(w_train)\n",
    ")\n",
    "mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab30162",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (y_valid - mean_pred) / y_valid\n",
    "# diff = (y_valid - mean_pred)\n",
    "print(1.5 * MAD(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72571d95",
   "metadata": {},
   "source": [
    "# Weighted linear least-squares method for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement \n",
    "Ks = 2 ** np.arange(0, int(np.log2(maxK)) + 1, 2)\n",
    "n_xps = [2, 8, 32, 64]\n",
    "\n",
    "y_valid_preds = {(n_xp, k): np.zeros(len(f_valid)) for k in Ks for n_xp in n_xps}\n",
    "# weighted_lls_errs = {}\n",
    "\n",
    "# TODO: Regularization\n",
    "alpha = 1e-8\n",
    "\n",
    "for n_xp in n_xps:\n",
    "    f_train_cut = f_train.slice_bp(n_xp).slice_rp(n_xp)\n",
    "    f_valid_cut = f_valid.slice_bp(n_xp).slice_rp(n_xp)\n",
    "    \n",
    "    X_fit_train = np.hstack((np.ones(f_train_cut.X.shape[0])[:, None], f_train_cut.X))\n",
    "    X_fit_valid = np.hstack((np.ones(f_valid_cut.X.shape[0])[:, None], f_valid_cut.X))\n",
    "    Nvalid = X_fit_valid.shape[0]\n",
    "    \n",
    "    L = np.eye(X_fit_train.shape[1]) * alpha\n",
    "    Linv = np.eye(X_fit_train.shape[1]) * 1 / alpha\n",
    "\n",
    "    for k in Ks:\n",
    "        # TODO: switch to linalg.lstsq when you hit singular matrix shit\n",
    "        for ii, ind in tqdm(enumerate(inds[:, :k]), total=Nvalid):\n",
    "            C_train = np.diag(1 / w_train[ind])\n",
    "            Cinv_train = np.diag(w_train[ind])\n",
    "\n",
    "            if k > n_xp:\n",
    "                y_valid_preds[n_xp, k][ii] = (\n",
    "                    X_fit_valid[ii] @ np.linalg.solve(\n",
    "                        X_fit_train[ind].T @ Cinv_train @ X_fit_train[ind] + L,\n",
    "                        X_fit_train[ind].T @ Cinv_train @ y_train[ind]\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                y_valid_preds[n_xp, k][ii] = (\n",
    "                    X_fit_valid[ii] @ Linv @ X_fit_train[ind].T @ np.linalg.solve(\n",
    "                        X_fit_train[ind] @ Linv @ X_fit_train[ind].T + C_train,\n",
    "                        y_train[ind]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # BUG: The next line is WRONG\n",
    "    #     weighted_lls_errs[k] = np.sqrt(1 / np.sum(W_train[inds[:, :k]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    len(Ks), len(n_xps), \n",
    "    figsize=(12, 12),\n",
    "    sharex=True, sharey=True,\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "for i, P in enumerate(n_xps):\n",
    "    for j, k in enumerate(Ks):\n",
    "        ax = axes[j, i]\n",
    "        \n",
    "        # dy = (Y_valid - Y_valid_preds[P, k]) / Y_valid\n",
    "        dy = (y_valid - y_valid_preds[P, k]) \n",
    "\n",
    "        _cs = ax.scatter(\n",
    "            bprp[valid],\n",
    "            mg[valid],\n",
    "            c=dy,\n",
    "            vmin=-0.25, vmax=0.25,\n",
    "            cmap='RdBu',\n",
    "            s=1\n",
    "        )\n",
    "\n",
    "        ax.set_xlim(0., 4.)\n",
    "        ax.set_ylim(10, -4)\n",
    "\n",
    "        ax.set_title(f'K={k}, P={P}')\n",
    "\n",
    "for ax in axes[-1]:\n",
    "    ax.set_xlabel('$G_{BP}-G_{RP}$')\n",
    "for ax in axes[:, 0]:\n",
    "    ax.set_ylabel('$M_G$')\n",
    "\n",
    "cb = fig.colorbar(_cs, ax=axes, aspect=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _cs = plt.scatter(\n",
    "#     bprp[valid],\n",
    "#     mg[valid],\n",
    "#     c=Y_valid_preds[3, 64] - Y_valid_preds[101, 64],\n",
    "#     vmin=-10, vmax=10,\n",
    "#     cmap='RdBu',\n",
    "#     s=1\n",
    "# )\n",
    "\n",
    "# plt.xlim(0., 4.)\n",
    "# plt.ylim(10, -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6aff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, P in enumerate(n_xps):\n",
    "    for j, k in enumerate(ks):\n",
    "        diff = (y_valid - y_valid_preds[P, k]) / y_valid\n",
    "#         diff = (y_valid - y_valid_preds[P, k])\n",
    "        print(P, k, 1.5 * np.median(np.abs(diff - np.median(diff))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1bc441",
   "metadata": {},
   "source": [
    "2D \"image\" of P vs K, colored by metric (MAD, RMS) in MS box and RGB box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_boxes = {\n",
    "    'ms': (\n",
    "        (np.abs(bprp - 1.5) < 0.5) &\n",
    "        (np.abs(mg - 7) < 0.5)\n",
    "    ),\n",
    "    'rc': (\n",
    "        (np.abs(bprp - 1.2) < 0.5) &\n",
    "        (np.abs(mg - 0.9) < 0.5)\n",
    "    ),\n",
    "    'rgb': (\n",
    "        (np.abs(bprp - 1.2) < 0.5) &\n",
    "        (np.abs(mg - 1) < 0.5)\n",
    "    ),\n",
    "    'trgb': (\n",
    "        (bprp > 1) &\n",
    "        (bprp < 4) &\n",
    "        (np.abs(mg - -1) < 0.5)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "for name, box_mask in stat_boxes.items():\n",
    "    stats[name] = np.zeros((len(n_xps), len(Ks)))\n",
    "    for i, P in enumerate(n_xps):\n",
    "        for j, k in enumerate(ks):\n",
    "            chi = (np.sqrt(w_valid) * (y_valid - y_valid_preds[P, k]))[box_mask[valid]]\n",
    "            meanchi2 = np.mean(chi**2)\n",
    "            medchi2 = np.median(chi**2)\n",
    "\n",
    "            stats[name][i, j] = meanchi2\n",
    "#             stats[name][i, j] = medchi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47685497",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(11, 10), \n",
    "                         sharex=True, sharey=True,\n",
    "                         constrained_layout=True)\n",
    "for ax, (name, stat) in zip(axes.flat, stats.items()):\n",
    "    _cs = ax.imshow(stat.T, cmap='turbo', origin='lower')\n",
    "    fig.colorbar(_cs, ax=ax)\n",
    "    ax.set_xlabel('$P$')\n",
    "    ax.set_ylabel('$k$')\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(n_xps)))\n",
    "    ax.set_yticks(np.arange(len(Ks)))\n",
    "    ax.set_xticklabels([str(x) for x in n_xps])\n",
    "    ax.set_yticklabels([str(x) for x in Ks])\n",
    "    \n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea716f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, stat in stats.items():\n",
    "#     fig, ax = plt.subplots(figsize=(6.5, 5.5), constrained_layout=True)\n",
    "#     _cs = plt.imshow(stat.T, cmap='turbo', origin='lower')\n",
    "#     fig.colorbar(_cs, ax=ax)\n",
    "#     ax.set_xlabel('$P$')\n",
    "#     ax.set_ylabel('$k$')\n",
    "    \n",
    "#     ax.set_xticks(np.arange(len(Ps)))\n",
    "#     ax.set_yticks(np.arange(len(ks)))\n",
    "#     ax.set_xticklabels([str(x) for x in Ps])\n",
    "#     ax.set_yticklabels([str(x) for x in ks])\n",
    "    \n",
    "#     ax.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc839969",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8814e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_mask[valid].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a linear weighted least squares as a function of k\n",
    "# HOGG: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some kind of mixture model maybe??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8ec2a",
   "metadata": {},
   "source": [
    "## Run this model on EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86404e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APW: We need to figure out the above tests and then run in the data center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f8897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735673a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adrian conda base",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
