{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b6ea29",
   "metadata": {},
   "source": [
    "# Linear Latent Variable Model\n",
    "See the Text.\n",
    "\n",
    "## TODO / questions\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53898a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import jax\n",
    "import jaxopt\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from schlummernd import LinearLVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "renorm = np.sqrt(np.sum(self.A[:, self.free_elements_of_Z] ** 2, axis=0))\n",
    "        self.A.at[:, self.free_elements_of_Z].divide(renorm[None, :])\n",
    "        self.Z.at[:, self.free_elements_of_Z].multiply(renorm[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc24fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "from dataclasses import dataclass\n",
    "from typing import Annotated, Any, Dict, get_args\n",
    "\n",
    "# Third-party\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from schlummernd import ParameterState\n",
    "from schlummernd.lvm import _model_linear\n",
    "\n",
    "\n",
    "class LinearLVM2:\n",
    "\n",
    "    def __init__(self, X, y, X_err, y_err, B, alpha, beta,\n",
    "                 verbose=False, rng=None):\n",
    "        \"\"\"\n",
    "        N - stars\n",
    "        R - features\n",
    "        Q - labels\n",
    "        D - latents\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            shape `(N, R)` array of training features\n",
    "        y : array-like\n",
    "            shape `(N, Q)` array of training labels\n",
    "        X_err : array-like\n",
    "            shape `(N, R)` array of errors (standard deviations) for the features\n",
    "        y_err : array-like\n",
    "            shape `(N, Q)` array of errors (standard deviations) for the labels\n",
    "        B : array-like\n",
    "            shape `(Q, D)` matrix translating latents to labels.\n",
    "        alpha : numeric\n",
    "            regularization strength; use the source, Luke.\n",
    "        beta : numeric\n",
    "            burp.\n",
    "        \"\"\"\n",
    "        self.verbose = verbose\n",
    "        if rng is None:\n",
    "            rng = np.random.default_rng()\n",
    "        self.rng = rng\n",
    "\n",
    "        self.X = jnp.array(X)\n",
    "        self.y = jnp.array(y)\n",
    "        self.X_err = jnp.array(X_err)\n",
    "        self.y_err = jnp.array(y_err)\n",
    "\n",
    "        self.sizes = {}\n",
    "        self.sizes['N'], self.sizes['R'] = self.X.shape\n",
    "        self.sizes['Q'] = self.y.shape[1]\n",
    "\n",
    "        shp_msg = \"Invalid shape for {object_name}: got {got}, expected {expected})\"\n",
    "        if self.y.shape[0] != self.sizes['N']:\n",
    "            shp_msg.format(\n",
    "                object_name=\"training labels y\",\n",
    "                got=self.y.shape[0],\n",
    "                expected=self.sizes['N']\n",
    "            )\n",
    "        if self.X_err.shape != self.X.shape:\n",
    "            shp_msg.format(\n",
    "                object_name=\"X_err\",\n",
    "                got=self.X_err.shape,\n",
    "                expected=self.X.shape\n",
    "            )\n",
    "        if self.y_err.shape != self.y.shape:\n",
    "            shp_msg.format(\n",
    "                object_name=\"y_err\",\n",
    "                got=self.y_err.shape,\n",
    "                expected=self.y.shape\n",
    "            )\n",
    "\n",
    "        self._X_ivar = 1 / self.X_err**2\n",
    "        self._y_ivar = 1 / self.y_err**2\n",
    "\n",
    "        # B turned into a Jax array below\n",
    "        B = np.array(B, copy=True)\n",
    "        _, self.sizes['D'] = B.shape\n",
    "        if B.shape[0] != self.sizes['Q']:\n",
    "            shp_msg.format(\n",
    "                object_name=\"B\",\n",
    "                got=B.shape[0],\n",
    "                expected=self.sizes['Q']\n",
    "            )\n",
    "\n",
    "        # Elements of B that we will fit for should be set to nan in the input B array\n",
    "        self._B_fit_mask = jnp.isnan(B)\n",
    "        if not np.any(self._B_fit_mask) and verbose:\n",
    "            print(\"no free elements of B\")\n",
    "        elif np.any(self._B_fit_mask):\n",
    "            B[self._B_fit_mask] = 0.\n",
    "            if verbose:\n",
    "                print(f\"using {self._B_fit_mask.sum()} free elements of B\")\n",
    "        self.B = jnp.array(B)\n",
    "        if verbose:\n",
    "            print(f\"B = {B}\")\n",
    "            print(f\"B fit elements = {self._B_fit_mask}\")\n",
    "\n",
    "        # Now assess which latents to fit:\n",
    "        self._z_fit_mask = jnp.all(self.B == 0, axis=0)\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"using {self._z_fit_mask.sum()} unconstrained elements of z, \"\n",
    "                f\"out of {self.sizes['D']} latents\"\n",
    "            )\n",
    "\n",
    "        self.alpha = float(alpha)\n",
    "        self.beta = float(beta)\n",
    "\n",
    "        # Regularization matrix:\n",
    "        self.Lambda = self.alpha * np.diag(self._z_fit_mask.astype(int))\n",
    "        if verbose:\n",
    "            print(f\"Lambda = {self.Lambda}\")\n",
    "        assert self.alpha > 0., \"You must regularize, and strictly positively.\"\n",
    "\n",
    "        # TODO:\n",
    "        self.par_state = self.initialize_par_state()\n",
    "\n",
    "    def initialize_par_state(self, **state):\n",
    "        \"\"\"\n",
    "        N - stars\n",
    "        R - features\n",
    "        Q - labels\n",
    "        D - latents\n",
    "        \n",
    "        mu_X : (R, )\n",
    "        mu_y : (Q, )\n",
    "        z : (N, D)\n",
    "        A : (R, D)\n",
    "        B : (Q, D)\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the means using invvar weighted means\n",
    "        # TODO: could do sigma-clipping here to be more robust\n",
    "        if 'mu_X' not in state:\n",
    "            state['mu_X'] = (\n",
    "                jnp.sum(self.X * self._X_ivar, axis=0) /\n",
    "                jnp.sum(self._X_ivar, axis=0)\n",
    "            )\n",
    "\n",
    "        if 'mu_y' not in state:\n",
    "            state['mu_y'] = (\n",
    "                jnp.sum(self.y * self._y_ivar, axis=0) /\n",
    "                jnp.sum(self._y_ivar, axis=0)\n",
    "            )\n",
    "\n",
    "        if 'z' not in state:\n",
    "            # First hack: Start with the pseudo-inverse of `B`.\n",
    "            state['z'] = np.zeros((self.sizes['N'], self.sizes['D']))\n",
    "            chi = (self.y - state['mu_y'][None]) / self.y_err\n",
    "            for n in range(self.sizes['N']):\n",
    "                state['z'][n] = jnp.linalg.lstsq(\n",
    "                    self.B / self.y_err[n][:, None],\n",
    "                    chi[n],\n",
    "                    rcond=None\n",
    "                )[0].T\n",
    "                \n",
    "            # Second hack: Add some noise to unconstrained z components\n",
    "            sigma = np.std(state['z'][:, ~self._z_fit_mask], axis=0)\n",
    "            scale = 0.1  # MAGIC NUMBER\n",
    "            state['z'][:, ~self._z_fit_mask] += self.rng.normal(\n",
    "                0, \n",
    "                scale * sigma, \n",
    "                size=(self.sizes['N'], (~self._z_fit_mask).sum())\n",
    "            )\n",
    "            \n",
    "            state['z'][:, self._z_fit_mask] = self.rng.normal(\n",
    "                0, \n",
    "                scale * np.mean(sigma), \n",
    "                size=(self.sizes['N'], self._z_fit_mask.sum())\n",
    "            )\n",
    "\n",
    "        if 'A' not in state:\n",
    "            state['A'] = np.zeros((self.sizes['R'], self.sizes['D']))\n",
    "            chi = self._chi_X(state['mu_X'], state['A'], state['z'])\n",
    "            \n",
    "            for r in range(self.sizes['R']):\n",
    "                state['A'][r] = jnp.linalg.lstsq(\n",
    "                    state['z'] /  self.X_err[:, r:r+1],\n",
    "                    chi[:, r],\n",
    "                    rcond=None\n",
    "                )[0]\n",
    "            \n",
    "        renorm = np.sqrt(np.sum(state['A'][:, self._z_fit_mask]**2, axis=0))\n",
    "        state['A'][:, self._z_fit_mask] = state['A'][:, self._z_fit_mask] / renorm[None, :]\n",
    "        state['z'][:, self._z_fit_mask] = state['z'][:, self._z_fit_mask] * renorm[None, :]\n",
    "\n",
    "        if 'B' not in state:\n",
    "            # TODO: implement this\n",
    "            state['B'] = self.B\n",
    "\n",
    "        return ParameterState(sizes=self.sizes, **state)\n",
    "\n",
    "    def _chi_X(self, mu_X, A, z):\n",
    "        return (self.X - _model_linear(mu_X, A, z)) / self.X_err\n",
    "\n",
    "    def _chi_y(self, mu_y, B, z):\n",
    "        return (self.y - _model_linear(mu_y, B, z)) / self.y_err\n",
    "\n",
    "    def unpack_p(self, p):\n",
    "        \"\"\"\n",
    "        TODO: deal with some of B is frozen\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        state = {}\n",
    "        for name in self.par_state.names:\n",
    "            if name == 'B':\n",
    "                # TODO: see note above\n",
    "                state['B'] = self.par_state.B\n",
    "                continue\n",
    "                \n",
    "            # HACK: REMOVE ME\n",
    "#             elif name == 'mu_X':\n",
    "#                 state['mu_X'] = self.par_state.mu_X\n",
    "#                 continue\n",
    "#             elif name == 'mu_y':\n",
    "#                 state['mu_y'] = self.par_state.mu_y\n",
    "#                 continue\n",
    "\n",
    "            val = getattr(self.par_state, name)\n",
    "            state[name] = p[i:i+val.size].reshape(val.shape)\n",
    "            i += val.size\n",
    "        return ParameterState(sizes=self.sizes, **state)\n",
    "\n",
    "    def pack_p(self, par_state=None):\n",
    "        \"\"\"\n",
    "        TODO: deal with some of B is frozen\n",
    "        \"\"\"\n",
    "        if par_state is None:\n",
    "            par_state = self.par_state\n",
    "\n",
    "        arrs = []\n",
    "        for name in par_state.names:\n",
    "            if name == 'B':\n",
    "                # TODO: deal with note above\n",
    "                continue\n",
    "                \n",
    "            # HACK: REMOVE ME\n",
    "#             elif name in ['mu_X', 'mu_Y']:\n",
    "#                 continue\n",
    "                \n",
    "            val = getattr(par_state, name).flatten()\n",
    "            arrs.append(val)\n",
    "        return jnp.concatenate(arrs)\n",
    "\n",
    "    def cost(self, p):\n",
    "        \"\"\"\n",
    "        TODO: Regularization term is totally wrong.\n",
    "        \"\"\"\n",
    "        pars = self.unpack_p(p)\n",
    "        # TODO: set par_state??\n",
    "\n",
    "        chi_X = self._chi_X(pars.mu_X, pars.A, pars.z)\n",
    "        chi_y = self._chi_y(pars.mu_y, pars.B, pars.z)\n",
    "        \n",
    "        return 0.5 * (\n",
    "            jnp.sum(chi_X ** 2) +\n",
    "            jnp.sum(chi_y ** 2) +\n",
    "            self.alpha * jnp.sum(pars.z[:, self._z_fit_mask] ** 2) +\n",
    "            self.beta * jnp.sum(pars.A[:, self._z_fit_mask] ** 2)\n",
    "        )\n",
    "\n",
    "    def __call__(self, p):\n",
    "        val = self.cost(p)\n",
    "        return val\n",
    "\n",
    "    def predict_y(self, X, X_err, par_state=None):\n",
    "        if par_state is None:\n",
    "            par_state = self.par_state\n",
    "\n",
    "        # should this use the regularization matrix? Hogg thinks not.\n",
    "        M = X.shape[0]\n",
    "        if X.shape[1] != self.sizes['R']:\n",
    "            raise ValueError(\"Invalid shape for input feature matrix X\")\n",
    "\n",
    "        y_hat = np.zeros((M, self.sizes['Q']))\n",
    "\n",
    "        chi = (X - par_state.mu_X[None]) / X_err\n",
    "        for i, dx in enumerate(chi):\n",
    "            M = par_state.A / X_err[i][:, None]\n",
    "            z = np.linalg.lstsq(M, dx, rcond=None)[0]\n",
    "            y_hat[i] = par_state.mu_y + par_state.B @ z\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b006b31",
   "metadata": {},
   "source": [
    "# Make toy fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N - stars\n",
    "# R - features\n",
    "# Q - labels\n",
    "# D - latents\n",
    "\n",
    "N = 1024\n",
    "R = 32\n",
    "Q = 3\n",
    "D = 5\n",
    "M = 128\n",
    "\n",
    "# N = 191\n",
    "# R = 17\n",
    "# Q = 3\n",
    "# D = 5\n",
    "# M = 53\n",
    "\n",
    "# ---\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "A_true = rng.normal(size=(R, D))\n",
    "B_true = np.zeros((Q, D))\n",
    "B_true[:Q, :Q] = np.eye(Q)\n",
    "z_true = rng.normal(size=(N, D))\n",
    "\n",
    "mu_X = rng.uniform(-1, 1, size=(1, R))\n",
    "mu_y = rng.uniform(-1, 1, size=(1, Q))\n",
    "\n",
    "X_true = mu_X + z_true @ A_true.T\n",
    "y_true = mu_y + z_true @ B_true.T\n",
    "\n",
    "sigma = 0.1\n",
    "X = rng.normal(X_true, sigma, size=X_true.shape)  # Noisify\n",
    "y = rng.normal(y_true, sigma, size=y_true.shape)  # Noisify\n",
    "\n",
    "\n",
    "z_star_true = rng.normal(size=(M, D))\n",
    "X_star_true = mu_X + z_star_true @ A_true.T\n",
    "y_star_true = mu_y + z_star_true @ B_true.T\n",
    "X_star = rng.normal(X_star_true, sigma, size=X_star_true.shape)  # Noisify\n",
    "y_star = rng.normal(y_star_true, sigma, size=y_star_true.shape)  # Noisify\n",
    "\n",
    "X_err = np.full_like(X, sigma)\n",
    "y_err = np.full_like(y, sigma)\n",
    "X_star_err = np.full_like(X_star, sigma)\n",
    "y_star_err = np.full_like(y_star, sigma)\n",
    "\n",
    "alpha = 0.1\n",
    "beta = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75322fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "# llvm = LinearLVM(X, y, X_err, y_err, B_true, alpha, beta, verbose=True, rng=rng)\n",
    "llvm = LinearLVM2(X, y, X_err, y_err, B_true, alpha, beta, verbose=True, rng=rng)\n",
    "# llvm = LinearLVM(X, y, X_err, y_err, B_true, 0.1, 0., verbose=True, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8844b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chix = np.asarray(llvm._chi_X(llvm.par_state.mu_X, llvm.par_state.A, llvm.par_state.z))\n",
    "np.std(chix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a463c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = llvm.pack_p()\n",
    "llvm(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in llvm.par_state.names:\n",
    "#     assert np.all(getattr(llvm.unpack_p(llvm.pack_p()), name) == getattr(llvm.par_state, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = jaxopt.LBFGS(fun=llvm, maxiter=1000)\n",
    "res = solver.run(x0)\n",
    "res.state.iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201bd115",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    llvm(x0),\n",
    "    llvm(res.params)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_state = llvm.unpack_p(res.params)\n",
    "ystar_predict0 = llvm.predict_y(X_star, X_star_err, llvm.par_state)\n",
    "ystar_predict = llvm.predict_y(X_star, X_star_err, res_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer for test-set objects\n",
    "for k in range(y_star.shape[1]):\n",
    "    plt.figure()\n",
    "#     plt.scatter(y_star[:, k], ystar_predict0[:, k], c=\"r\", marker=\"o\")\n",
    "    plt.scatter(y_star[:, k], ystar_predict[:, k], c=\"k\", marker=\"o\")\n",
    "    plt.plot([y_star[:, k].min(), y_star[:, k].max()],\n",
    "             [y_star[:, k].min(), y_star[:, k].max()], \n",
    "             marker='', color='tab:blue')\n",
    "    plt.xlabel(f\"true label {k}\")\n",
    "    plt.ylabel(f\"prediction of label {k}\")\n",
    "    plt.title(\"held-out data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8b51e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1024\n",
    "R = 32\n",
    "Q = 3\n",
    "D = 5\n",
    "M = 100\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "A_true = rng.normal(size=(R, D))\n",
    "B_true = np.zeros((Q, D))\n",
    "B_true[:Q, :Q] = np.eye(Q)\n",
    "z_true = rng.normal(size=(N, D))\n",
    "\n",
    "X_true = z_true @ A_true.T\n",
    "y_true = z_true @ B_true.T\n",
    "\n",
    "sigma = 0.1\n",
    "X_train = rng.normal(X_true, sigma, size=X_true.shape)  # Noisify\n",
    "y_train = rng.normal(y_true, sigma, size=y_true.shape)  # Noisify\n",
    "\n",
    "\n",
    "z_valid_true = rng.normal(size=(M, D))\n",
    "X_valid_true = z_valid_true @ A_true.T\n",
    "y_valid_true = z_valid_true @ B_true.T\n",
    "X_valid = rng.normal(X_valid_true, sigma, size=X_valid_true.shape)  # Noisify\n",
    "y_valid = rng.normal(y_valid_true, sigma, size=y_valid_true.shape)  # Noisify\n",
    "\n",
    "X_train_err = np.full_like(X, sigma)\n",
    "y_train_err = np.full_like(y, sigma)\n",
    "X_valid_err = np.full_like(X_valid, sigma)\n",
    "y_valid_err = np.full_like(y_valid, sigma)\n",
    "\n",
    "alpha = 0.1\n",
    "beta = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n_labels = y_train.shape[1]\n",
    "n_latents = n_labels + 1\n",
    "B = np.zeros((n_labels, n_latents))\n",
    "B[:n_labels, :n_labels] = np.eye(n_labels)\n",
    "\n",
    "llvm = LinearLVM(\n",
    "    X_train, y_train, \n",
    "    X_train_err, y_train_err, \n",
    "    B, alpha=1, beta=1., \n",
    "    verbose=True, rng=rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = llvm.pack_p()\n",
    "print(llvm(x0))\n",
    "print(x0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = jaxopt.LBFGS(fun=llvm, maxiter=10000)\n",
    "res_bfgs = solver.run(x0)\n",
    "res_state = llvm.unpack_p(res_bfgs.params)\n",
    "print(res_bfgs.state.iter_num)\n",
    "llvm(res_bfgs.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6015ba95",
   "metadata": {},
   "source": [
    "### Self-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict0 = llvm.predict_y(\n",
    "    X_train, \n",
    "    X_train_err, \n",
    "    llvm.par_state\n",
    ")\n",
    "\n",
    "y_train_predict = llvm.predict_y(\n",
    "    X_train, \n",
    "    X_train_err,  \n",
    "    res_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c90626",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in range(y_train.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.scatter(\n",
    "        y_train[:, q],\n",
    "        y_train_predict0[:, q]\n",
    "    )\n",
    "    plt.scatter(\n",
    "        y_train[:, q],\n",
    "        y_train_predict[:, q]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer for test-set objects\n",
    "for k in range(y_valid.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.scatter(y_valid[:, k], y_valid_predict0[:, k], c=\"r\", marker=\"o\")\n",
    "    plt.scatter(y_valid[:, k], y_valid_predict[:, k], c=\"k\", marker=\"o\")\n",
    "    plt.plot([y_valid[:, k].min(), y_valid[:, k].max()],\n",
    "             [y_valid[:, k].min(), y_valid[:, k].max()], \n",
    "             marker='', color='tab:blue')\n",
    "    plt.xlabel(f\"true label {k}\")\n",
    "    plt.ylabel(f\"prediction of label {k}\")\n",
    "    plt.title(\"held-out data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_predict0 = llvm.predict_y(\n",
    "    X_valid, \n",
    "    X_valid_err, \n",
    "    llvm.par_state\n",
    ")\n",
    "\n",
    "y_valid_predict = llvm.predict_y(\n",
    "    X_valid, \n",
    "    X_valid_err, \n",
    "    res_state\n",
    ")\n",
    "\n",
    "print(y_valid)\n",
    "print(y_valid_predict0)\n",
    "print(y_valid_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6af8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8b5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adrian conda base",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
