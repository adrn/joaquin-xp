{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141e3a6d",
   "metadata": {},
   "source": [
    "# Experiments related to Joaquin\n",
    "Technically, this notebook implements something *even dumber* than *Joaquin*.\n",
    "It implements kNN in *Gaia*-only quantities to get weighted-mean and weighted-least squares estimates of schmag or schmarrn.\n",
    "\n",
    "## Authors:\n",
    "- **Adrian Price-Whelan** (Flatiron)\n",
    "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
    "\n",
    "## Hyper-parameters:\n",
    "- `ncoeff`: The maximum number of BP and RP spectral coefficients to use in the project.\n",
    "- `pee_tree`: The number of features to use in the kdtree.\n",
    "- `maxk`: The maximum `k` to which we take neighbors; various `k` values are attempted.\n",
    "- scalings or preprocessing of input features (currently just normalization by `RP[0]`).\n",
    "- how we use the neighbors (weighted mean, weighted linear fit, mixture of some kind?).\n",
    "\n",
    "## To-do items and bugs:\n",
    "- We currently take ALL neighbors. But we don't need to consider neighbors that have obviously discrepant schmags given the extant Gaia data. Should we cut on schmag? Maybe?? It's complicated.\n",
    "- Many of the KNN collections contain significant outliers. We should do something more robust than just WLS. Maybe some iteratively reweighted LS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f708a",
   "metadata": {},
   "source": [
    "## Read in and munge all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abaf192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import astropy.table as at\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27342cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"./\"\n",
    "xm = at.Table.read(datadir + 'allStar-dr17-synspec-gaiadr3.fits')\n",
    "xm2 = at.Table.read(datadir + 'allStar-dr17-synspec-gaiadr3-gaiasourcelite.fits')\n",
    "xm2.rename_column('source_id', 'GAIADR3_SOURCE_ID')\n",
    "allstar = at.Table.read(datadir + 'allStarLite-dr17-synspec_rev1.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f49147",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = at.unique(at.hstack((allstar, xm)), keys='APOGEE_ID')\n",
    "tbl = tbl[tbl['GAIADR3_SOURCE_ID'] != 0]\n",
    "tbl = at.join(tbl, xm2, keys='GAIADR3_SOURCE_ID')\n",
    "len(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451885dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "apogee_xp_cont_filename = pathlib.Path(datadir + 'apogee-dr17-xpcontinuous.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and lightly rearrange\n",
    "xp_tbl = at.Table()\n",
    "with h5py.File(apogee_xp_cont_filename, 'r') as f:\n",
    "    xp_tbl['GAIADR3_SOURCE_ID'] = f['source_id'][:]\n",
    "    xp_tbl['bp'] = f['bp_coefficients'][:]\n",
    "    xp_tbl['rp'] = f['rp_coefficients'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07051f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and make simple cuts\n",
    "# Hogg: Why these cuts?\n",
    "xp_apogee_tbl = at.join(tbl, xp_tbl, keys='GAIADR3_SOURCE_ID')\n",
    "xp_apogee_tbl = xp_apogee_tbl[\n",
    "    (xp_apogee_tbl['TEFF'] > 3500.) &\n",
    "    (xp_apogee_tbl['TEFF'] < 6000.) &\n",
    "    (xp_apogee_tbl['LOGG'] > -0.5) &\n",
    "    (xp_apogee_tbl['LOGG'] < 5.5) &\n",
    "    (xp_apogee_tbl['M_H'] > -2.)\n",
    "]\n",
    "len(xp_apogee_tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c0190",
   "metadata": {},
   "source": [
    "## Make rectangular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does something useful!\n",
    "xp_apogee_tbl = xp_apogee_tbl.filled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make rectangular block of Gaia-only features (X) for training and validation\n",
    "# Note the gymnastics around normalizing by RP[0].\n",
    "\n",
    "# APW, HOGG: BUG: Why these cuts?\n",
    "feature_mask = (\n",
    "    (xp_apogee_tbl['J'] < 13) &\n",
    "    (xp_apogee_tbl['H'] < 12) &\n",
    "    (xp_apogee_tbl['K'] < 11) &\n",
    "    (xp_apogee_tbl['AK_WISE'] > -0.1))\n",
    "\n",
    "ncoeff = 50 # MAGIC\n",
    "features = np.hstack((\n",
    "    (xp_apogee_tbl['phot_bp_mean_mag'] - xp_apogee_tbl['phot_rp_mean_mag'])[feature_mask, None],\n",
    "    (xp_apogee_tbl['bp'][:, 0:ncoeff] / xp_apogee_tbl['rp'][:, 0:1])[feature_mask],\n",
    "    (xp_apogee_tbl['rp'][:, 1:ncoeff + 1] / xp_apogee_tbl['rp'][:, 0:1])[feature_mask],\n",
    "))\n",
    "\n",
    "feature_names = np.concatenate((\n",
    "    ['$BP-RP$ (mag)', ],\n",
    "    [f'BP[{i}]' for i in range(0, ncoeff)],\n",
    "    [f'RP[{i}]' for i in range(1, ncoeff + 1)],\n",
    "))\n",
    "\n",
    "print(features.shape)\n",
    "print(len(feature_names), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange feature order because Hogg has issues\n",
    "\n",
    "index = np.concatenate((\n",
    "    [0, ], \n",
    "    *([i, ncoeff + i, ] for i in range(1, ncoeff + 1))\n",
    "))\n",
    "print(feature_names[index])\n",
    "\n",
    "features = features[:, index]\n",
    "feature_names = feature_names[index]\n",
    "print(features.shape, feature_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adcc42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of labels (and label weights), aligned with the features.\n",
    "\n",
    "# Divide by 100 mas to get into correct maggie units.\n",
    "schmag_factor = 10 ** (0.2 * xp_apogee_tbl['phot_g_mean_mag'].value) / 100.\n",
    "\n",
    "labels = (xp_apogee_tbl['parallax'].value * schmag_factor)[feature_mask]\n",
    "print(labels.shape)\n",
    "\n",
    "label_errors = (xp_apogee_tbl['parallax_error'].value * schmag_factor)[feature_mask]\n",
    "print(label_errors.shape)\n",
    "\n",
    "label_weights = 1. / (label_errors ** 2)\n",
    "print(label_weights.shape)\n",
    "\n",
    "label_name = '$G$-band schmag (absmgy$^{-1/2}$)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the labels aren't wack\n",
    "\n",
    "plt.scatter(labels, labels / label_errors, c=\"k\", s=1., alpha=0.05)\n",
    "plt.axhline(np.median(labels / label_errors), color=\"k\")\n",
    "plt.xlim(-10., 50.)\n",
    "plt.ylim(-10., 200.)\n",
    "plt.xlabel(label_name)\n",
    "plt.ylabel(\"label SNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c04b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the features aren't wack\n",
    "\n",
    "for i in range(min(16, features.shape[1])):\n",
    "    f = plt.figure()\n",
    "    foo = np.percentile(features[:, i], [2.5, 97.5])\n",
    "    lo = 0.5 * (foo[1] + foo[0]) - (foo[1] - foo[0])\n",
    "    hi = 0.5 * (foo[1] + foo[0]) + (foo[1] - foo[0])\n",
    "    plt.scatter(features[:, i], labels, c=\"k\", s=1., alpha=0.05)\n",
    "    plt.xlim(lo, hi)\n",
    "    plt.ylim(-10., 50.)\n",
    "    plt.xlabel(feature_names[i])\n",
    "    plt.ylabel(label_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51c41f",
   "metadata": {},
   "source": [
    "## Make training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut to eighths #MAGIC\n",
    "# BUG: Should fix random state more sensibly than this.\n",
    "\n",
    "np.random.seed(17)\n",
    "rando = np.random.randint(8, size=len(features))\n",
    "train = rando != 0\n",
    "valid = ~train\n",
    "X_train, X_valid = features[train], features[valid]\n",
    "Y_train, Y_valid = labels[train], labels[valid]\n",
    "W_train, W_valid = label_weights[train], label_weights[valid]\n",
    "print(X_train.shape, X_valid.shape)\n",
    "print(Y_train.shape, Y_valid.shape)\n",
    "print(W_train.shape, W_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07796f11",
   "metadata": {},
   "source": [
    "## Build a kNN model and validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all possibly useful validation-set neighbors up-front.\n",
    "# We'll use them in various ways below.\n",
    "pee_tree = 9 # magic\n",
    "maxk = 2 ** 12 # magic\n",
    "tree = KDTree(X_train[:, :pee_tree], leaf_size=32) # magic\n",
    "dists, inds = tree.query(X_valid[:, :pee_tree], k=maxk)\n",
    "print(X_valid.shape, dists.shape, inds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a few objects\n",
    "for jj in range(8):\n",
    "    ii = np.random.randint(len(Y_valid))\n",
    "    while Y_valid[ii] > 1.:\n",
    "        ii = np.random.randint(len(Y_valid))\n",
    "    ff = plt.figure()\n",
    "    plt.axhline(Y_valid[ii], c=\"r\")\n",
    "    plt.errorbar(dists[ii], Y_train[inds[ii]], yerr = 1. / np.sqrt(W_train[inds[ii]]),\n",
    "                 fmt=\"o\", color=\"k\", ecolor=\"k\")\n",
    "    plt.xlabel(\"distance to neighbor\")\n",
    "    plt.ylabel(\"label (schmag) of neighbor\")\n",
    "    plt.title(f\"validation-set object {ii}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted mean.\n",
    "# BUG: this is a bad idea!\n",
    "ks = 2 ** np.arange(5)\n",
    "Y_hat_mean, Y_hat_mean_ivar = {}, {}\n",
    "for k in Y_hat_mean.keys():\n",
    "    I = inds[:, :k]\n",
    "    Y_hat_mean_ivar[k] = np.sum(W_train[I], axis=1)\n",
    "    Y_hat_mean[k] = np.sum(W_train[I] * Y_train[I], axis=1) / Y_hat_mean_ivar[k]\n",
    "    print(k, Y_hat_mean[k].shape, Y_hat_mean_ivar[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ced68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma(ys, ys_true):\n",
    "    xs = (ys - ys_true) / (ys_true)\n",
    "    I = (ys_true > 0.5) & (ys_true < 2.0)\n",
    "    foo = np.percentile(xs[I], [16, 84])\n",
    "    return 0.5 * (foo[1] - foo[0])\n",
    "\n",
    "for k in Y_hat_mean.keys():\n",
    "    ff = plt.figure()\n",
    "    plt.plot([-100, 100], [-100, 100], \"k-\")\n",
    "    plt.plot(Y_valid, Y_hat_mean[k], \"k.\", alpha=0.1)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.xlim(-0.2, 2)\n",
    "    plt.ylim(-0.2, 2)\n",
    "    plt.xlabel(\"Gaia-measured schmag\")\n",
    "    plt.ylabel(\"weighted mean KNN predicted schmag\")\n",
    "    sigma = get_sigma(Y_hat_mean[k], Y_valid)\n",
    "    plt.title(\"mean of KNN, $k={0}$, fractional $\\sigma={1:4.2f}$\".format(k, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test unweighted median\n",
    "# BUG: this is a bad idea!\n",
    "Y_hat_med = {}\n",
    "for k in ks:\n",
    "    I = inds[:, :k]\n",
    "    Y_hat_med[k] = np.median(Y_train[I], axis=1)\n",
    "    print(k, Y_hat_med[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5620cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in Y_hat_med.keys():\n",
    "    ff = plt.figure()\n",
    "    plt.plot([-100, 100], [-100, 100], \"k-\")\n",
    "    plt.plot(Y_valid, Y_hat_med[k], \"k.\", alpha=0.1)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.xlim(-0.2, 2)\n",
    "    plt.ylim(-0.2, 2)\n",
    "    plt.xlabel(\"Gaia-measured schmag\")\n",
    "    plt.ylabel(\"median KNN predicted schmag\")\n",
    "    sigma = get_sigma(Y_hat_med[k], Y_valid)\n",
    "    plt.title(\"median of KNN, $k={0}$, fractional $\\sigma={1:4.2f}$\".format(k, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a linear weighted least squares as a function of k\n",
    "# BUG: UNTESTED\n",
    "# BUG: DOESN'T RETURN IVARS\n",
    "ks = 2 ** np.arange(9, 12)\n",
    "Y_hat_wls, Y_hat_wls_ivar = {}, {}\n",
    "for k in ks:\n",
    "    Y_hat_wls[k] = np.zeros_like(Y_valid) + np.NaN\n",
    "    I = inds[:, :k]\n",
    "    for i, II in enumerate(I):\n",
    "        # make design matrix\n",
    "        X = np.hstack((np.ones((k, 1)), X_train[II]))\n",
    "        Xstar = np.append(1, X_valid[i])\n",
    "        Cinv = W_train[II]\n",
    "        Y = Y_train[II]\n",
    "        Y_hat_wls[k][i] = Xstar @ np.linalg.lstsq(X.T @ (Cinv[:, None] * X),\n",
    "                                                  X.T @ (Cinv * Y),\n",
    "                                                  rcond=None)[0]\n",
    "    print(k, Y_hat_wls[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e41e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in Y_hat_wls.keys():\n",
    "    ff = plt.figure()\n",
    "    plt.plot([-100, 100], [-100, 100], \"k-\")\n",
    "    plt.plot(Y_valid, Y_hat_wls[k], \"k.\", alpha=0.1)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.xlim(-0.2, 2)\n",
    "    plt.ylim(-0.2, 2)\n",
    "    plt.xlabel(\"Gaia-measured schmag\")\n",
    "    plt.ylabel(\"WLS of KNN predicted schmag\")\n",
    "    sigma = get_sigma(Y_hat_wls[k], Y_valid)\n",
    "    plt.title(\"WLS of KNN, $k={0}$, fractional $\\sigma={1:4.2f}$\".format(k, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af396567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some kind of mixture model maybe??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e806cf1",
   "metadata": {},
   "source": [
    "## Run this model on EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ea9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APW: We need to figure out the above tests and then run in the data center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94704d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa9cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
